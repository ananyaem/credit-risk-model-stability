{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration\n",
        "\n",
        "Testing the data processing utilities with base table and static_0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"..\")\n",
        "\n",
        "import polars as pl\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from src.data_processing import (\n",
        "    load_table_group,\n",
        "    downcast_dtypes,\n",
        "    drop_high_missing_cols,\n",
        "    drop_high_cardinality_string_cols,\n",
        "    preprocess_table,\n",
        "    get_table_info,\n",
        ")\n",
        "from src.features import (\n",
        "    handle_dates, create_domain_ratios,\n",
        "    aggregate_depth1, aggregate_depth2,\n",
        "    drop_correlated_columns, collapse_rare_categories, remove_drift_features,\n",
        ")\n",
        "from src.metrics import gini_stability\n",
        "\n",
        "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
        "plt.rcParams.update({\"figure.dpi\": 120, \"figure.facecolor\": \"white\"})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_PATH = \"../data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Base Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the base table\n",
        "base = load_table_group(DATA_PATH, \"base\", split=\"train\")\n",
        "print(f\"Base table shape: {base.shape}\")\n",
        "base.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check base table info\n",
        "get_table_info(base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocess base table\n",
        "base_processed = preprocess_table(base)\n",
        "print(f\"\\nAfter preprocessing: {base_processed.shape}\")\n",
        "get_table_info(base_processed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Static_0 Table\n",
        "\n",
        "This table has multiple chunks (static_0_0, static_0_1, etc.) that need to be concatenated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load static_0 - this will concatenate all chunks\n",
        "static_0 = load_table_group(DATA_PATH, \"static_0\", split=\"train\")\n",
        "print(f\"Static_0 table shape: {static_0.shape}\")\n",
        "static_0.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check static_0 info before preprocessing\n",
        "info_before = get_table_info(static_0)\n",
        "print(f\"Shape: {info_before['shape']}\")\n",
        "print(f\"Memory: {info_before['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Dtype counts: {info_before['dtype_counts']}\")\n",
        "print(f\"Columns with >50% missing: {len(info_before['columns_with_high_missing'])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test downcast_dtypes\n",
        "static_0_downcasted = downcast_dtypes(static_0)\n",
        "info_downcasted = get_table_info(static_0_downcasted)\n",
        "print(f\"Memory before downcast: {info_before['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Memory after downcast: {info_downcasted['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Memory reduction: {(1 - info_downcasted['estimated_memory_mb']/info_before['estimated_memory_mb'])*100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test drop_high_missing_cols\n",
        "print(f\"Columns before: {static_0.shape[1]}\")\n",
        "static_0_no_missing = drop_high_missing_cols(static_0, threshold=0.98)\n",
        "print(f\"Columns after (threshold=0.98): {static_0_no_missing.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test drop_high_cardinality_string_cols\n",
        "static_0_no_high_card = drop_high_cardinality_string_cols(static_0, max_unique=10_000)\n",
        "print(f\"Columns after dropping high-cardinality strings: {static_0_no_high_card.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply full preprocessing pipeline\n",
        "static_0_processed = preprocess_table(static_0)\n",
        "print(f\"\\nFinal shape after full preprocessing: {static_0_processed.shape}\")\n",
        "get_table_info(static_0_processed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (a) Target Distribution & Temporal Drift"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "target_counts = base[\"target\"].value_counts().sort(\"target\").to_pandas()\n",
        "total = target_counts[\"count\"].sum()\n",
        "default_rate = target_counts.loc[target_counts[\"target\"] == 1, \"count\"].values[0] / total\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(13, 4))\n",
        "\n",
        "ax = axes[0]\n",
        "bars = ax.bar(\n",
        "    target_counts[\"target\"].astype(str),\n",
        "    target_counts[\"count\"],\n",
        "    color=[\"#4C72B0\", \"#DD8452\"],\n",
        "    edgecolor=\"black\",\n",
        "    linewidth=0.5,\n",
        ")\n",
        "for bar, count in zip(bars, target_counts[\"count\"]):\n",
        "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height(),\n",
        "            f\"{count:,}\\n({count/total:.1%})\", ha=\"center\", va=\"bottom\", fontsize=9)\n",
        "ax.set_xlabel(\"Target\")\n",
        "ax.set_ylabel(\"Count\")\n",
        "ax.set_title(f\"Target Distribution (default rate = {default_rate:.2%})\")\n",
        "ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
        "\n",
        "weekly = (\n",
        "    base.group_by(\"WEEK_NUM\")\n",
        "    .agg([\n",
        "        pl.col(\"target\").mean().alias(\"default_rate\"),\n",
        "        pl.col(\"target\").count().alias(\"n_cases\"),\n",
        "    ])\n",
        "    .sort(\"WEEK_NUM\")\n",
        "    .to_pandas()\n",
        ")\n",
        "\n",
        "ax = axes[1]\n",
        "ax.plot(weekly[\"WEEK_NUM\"], weekly[\"default_rate\"], color=\"#4C72B0\", linewidth=1.2)\n",
        "z = np.polyfit(weekly[\"WEEK_NUM\"], weekly[\"default_rate\"], 1)\n",
        "ax.plot(weekly[\"WEEK_NUM\"], np.polyval(z, weekly[\"WEEK_NUM\"]),\n",
        "        \"--\", color=\"#DD8452\", linewidth=1.5, label=f\"trend (slope={z[0]:.5f})\")\n",
        "ax.set_xlabel(\"WEEK_NUM\")\n",
        "ax.set_ylabel(\"Default Rate\")\n",
        "ax.set_title(\"Default Rate by Week (temporal drift)\")\n",
        "ax.legend(fontsize=9)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fig, ax = plt.subplots(figsize=(13, 3))\n",
        "ax.bar(weekly[\"WEEK_NUM\"], weekly[\"n_cases\"], color=\"#4C72B0\", edgecolor=\"none\", width=1.0)\n",
        "ax.set_xlabel(\"WEEK_NUM\")\n",
        "ax.set_ylabel(\"Number of Cases\")\n",
        "ax.set_title(\"Case Volume by Week\")\n",
        "ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (b) Missing Rates Across Table Groups"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "TABLE_GROUPS = [\n",
        "    \"base\", \"static_0\", \"static_cb_0\",\n",
        "    \"person_1\", \"person_2\",\n",
        "    \"applprev_1\", \"applprev_2\",\n",
        "    \"credit_bureau_a_1\", \"credit_bureau_a_2\",\n",
        "    \"credit_bureau_b_1\", \"credit_bureau_b_2\",\n",
        "    \"debitcard_1\", \"deposit_1\", \"other_1\",\n",
        "    \"tax_registry_a_1\", \"tax_registry_b_1\", \"tax_registry_c_1\",\n",
        "]\n",
        "\n",
        "missing_summary = []\n",
        "for tg in TABLE_GROUPS:\n",
        "    try:\n",
        "        df = load_table_group(DATA_PATH, tg, split=\"train\")\n",
        "    except FileNotFoundError:\n",
        "        continue\n",
        "    n = df.height\n",
        "    nc = df.null_count()\n",
        "    for col in df.columns:\n",
        "        if col == \"case_id\":\n",
        "            continue\n",
        "        rate = nc[col][0] / n\n",
        "        missing_summary.append({\"table_group\": tg, \"column\": col, \"missing_rate\": rate})\n",
        "\n",
        "missing_df = pl.DataFrame(missing_summary)\n",
        "print(f\"Total feature columns across all tables: {missing_df.height}\")\n",
        "print(f\"Columns with >50% missing: {missing_df.filter(pl.col('missing_rate') > 0.5).height}\")\n",
        "print(f\"Columns with >90% missing: {missing_df.filter(pl.col('missing_rate') > 0.9).height}\")\n",
        "print(f\"Columns with >98% missing: {missing_df.filter(pl.col('missing_rate') > 0.98).height}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "table_miss = (\n",
        "    missing_df.group_by(\"table_group\")\n",
        "    .agg([\n",
        "        pl.col(\"missing_rate\").mean().alias(\"avg_missing\"),\n",
        "        pl.col(\"missing_rate\").max().alias(\"max_missing\"),\n",
        "        (pl.col(\"missing_rate\") > 0.98).sum().alias(\"cols_gt_98pct\"),\n",
        "        pl.len().alias(\"n_cols\"),\n",
        "    ])\n",
        "    .sort(\"avg_missing\", descending=True)\n",
        "    .to_pandas()\n",
        ")\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.barh(table_miss[\"table_group\"], table_miss[\"avg_missing\"], color=\"#4C72B0\", edgecolor=\"none\")\n",
        "ax.set_xlabel(\"Average Missing Rate\")\n",
        "ax.set_title(\"Average Missing Rate per Table Group\")\n",
        "ax.invert_yaxis()\n",
        "ax.axvline(0.5, color=\"grey\", linestyle=\"--\", linewidth=0.8, alpha=0.7)\n",
        "\n",
        "ax = axes[1]\n",
        "colors = [\"#DD8452\" if v > 0 else \"#4C72B0\" for v in table_miss[\"cols_gt_98pct\"]]\n",
        "ax.barh(table_miss[\"table_group\"], table_miss[\"cols_gt_98pct\"], color=colors, edgecolor=\"none\")\n",
        "ax.set_xlabel(\"Number of Columns\")\n",
        "ax.set_title(\"Columns with >98% Missing per Table Group\")\n",
        "ax.invert_yaxis()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "top_missing = (\n",
        "    missing_df.filter(pl.col(\"missing_rate\") > 0.90)\n",
        "    .sort(\"missing_rate\", descending=True)\n",
        ")\n",
        "print(f\"Columns with >90% missing ({top_missing.height} total):\")\n",
        "print(top_missing.head(30))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (c) Feature Drift Detection\n",
        "\n",
        "Compare numeric feature distributions in **early weeks** (WEEK_NUM 0–30) vs **late weeks** (WEEK_NUM 61–91).\n",
        "For each feature we measure:\n",
        "- **Relative shift in mean**: `|mean_late - mean_early| / (std_overall + ε)`\n",
        "- **Relative shift in std**: `|std_late - std_early| / (std_overall + ε)`\n",
        "- **Shift in missing rate**: `|miss_late - miss_early|`\n",
        "\n",
        "Features with large shifts are candidates for dropping to improve model stability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "static_with_week = static_0.join(\n",
        "    base.select(\"case_id\", \"WEEK_NUM\"), on=\"case_id\", how=\"left\"\n",
        ")\n",
        "\n",
        "numeric_cols = [\n",
        "    c for c in static_0.columns\n",
        "    if c != \"case_id\" and static_0[c].dtype in (pl.Float64, pl.Float32, pl.Int64, pl.Int32)\n",
        "]\n",
        "print(f\"Numeric columns to analyze: {len(numeric_cols)}\")\n",
        "\n",
        "EARLY_MAX = 30\n",
        "LATE_MIN = 61\n",
        "\n",
        "early = static_with_week.filter(pl.col(\"WEEK_NUM\") <= EARLY_MAX)\n",
        "late = static_with_week.filter(pl.col(\"WEEK_NUM\") >= LATE_MIN)\n",
        "print(f\"Early weeks (0-{EARLY_MAX}): {early.height:,} rows\")\n",
        "print(f\"Late weeks ({LATE_MIN}-91): {late.height:,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "EPS = 1e-9\n",
        "drift_records = []\n",
        "\n",
        "overall_stats = static_0.select([\n",
        "    pl.col(c).cast(pl.Float64).std().alias(f\"{c}__std\") for c in numeric_cols\n",
        "])\n",
        "\n",
        "for col in numeric_cols:\n",
        "    std_all = overall_stats[f\"{col}__std\"][0]\n",
        "    if std_all is None:\n",
        "        continue\n",
        "    std_all = float(std_all)\n",
        "\n",
        "    mean_e = early[col].cast(pl.Float64).mean()\n",
        "    mean_l = late[col].cast(pl.Float64).mean()\n",
        "    std_e = early[col].cast(pl.Float64).std()\n",
        "    std_l = late[col].cast(pl.Float64).std()\n",
        "    miss_e = early[col].null_count() / early.height\n",
        "    miss_l = late[col].null_count() / late.height\n",
        "\n",
        "    if mean_e is None or mean_l is None:\n",
        "        continue\n",
        "\n",
        "    mean_shift = abs(mean_l - mean_e) / (std_all + EPS)\n",
        "    std_shift = abs((std_l or 0) - (std_e or 0)) / (std_all + EPS)\n",
        "    miss_shift = abs(miss_l - miss_e)\n",
        "\n",
        "    drift_records.append({\n",
        "        \"column\": col,\n",
        "        \"mean_early\": round(mean_e, 4),\n",
        "        \"mean_late\": round(mean_l, 4),\n",
        "        \"mean_shift\": round(mean_shift, 4),\n",
        "        \"std_shift\": round(std_shift, 4),\n",
        "        \"miss_early\": round(miss_e, 4),\n",
        "        \"miss_late\": round(miss_l, 4),\n",
        "        \"miss_shift\": round(miss_shift, 4),\n",
        "    })\n",
        "\n",
        "drift_df = pl.DataFrame(drift_records).sort(\"mean_shift\", descending=True)\n",
        "print(f\"Analyzed {drift_df.height} numeric features for drift\")\n",
        "drift_df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "top_n = 25\n",
        "top_drift = drift_df.head(top_n).to_pandas()\n",
        "\n",
        "fig, axes = plt.subplots(1, 3, figsize=(17, 6))\n",
        "\n",
        "ax = axes[0]\n",
        "ax.barh(top_drift[\"column\"], top_drift[\"mean_shift\"], color=\"#DD8452\", edgecolor=\"none\")\n",
        "ax.set_xlabel(\"Normalised Mean Shift\")\n",
        "ax.set_title(f\"Top {top_n} Features by Mean Drift\")\n",
        "ax.invert_yaxis()\n",
        "\n",
        "top_std = drift_df.sort(\"std_shift\", descending=True).head(top_n).to_pandas()\n",
        "ax = axes[1]\n",
        "ax.barh(top_std[\"column\"], top_std[\"std_shift\"], color=\"#55A868\", edgecolor=\"none\")\n",
        "ax.set_xlabel(\"Normalised Std Shift\")\n",
        "ax.set_title(f\"Top {top_n} Features by Std Drift\")\n",
        "ax.invert_yaxis()\n",
        "\n",
        "top_miss = drift_df.sort(\"miss_shift\", descending=True).head(top_n).to_pandas()\n",
        "ax = axes[2]\n",
        "ax.barh(top_miss[\"column\"], top_miss[\"miss_shift\"], color=\"#8172B2\", edgecolor=\"none\")\n",
        "ax.set_xlabel(\"Δ Missing Rate\")\n",
        "ax.set_title(f\"Top {top_n} Features by Missing-Rate Shift\")\n",
        "ax.invert_yaxis()\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "MEAN_SHIFT_THRESHOLD = 0.3\n",
        "STD_SHIFT_THRESHOLD = 0.3\n",
        "MISS_SHIFT_THRESHOLD = 0.1\n",
        "\n",
        "drift_flagged = drift_df.filter(\n",
        "    (pl.col(\"mean_shift\") > MEAN_SHIFT_THRESHOLD)\n",
        "    | (pl.col(\"std_shift\") > STD_SHIFT_THRESHOLD)\n",
        "    | (pl.col(\"miss_shift\") > MISS_SHIFT_THRESHOLD)\n",
        ").sort(\"mean_shift\", descending=True)\n",
        "\n",
        "print(f\"Features flagged for drift (any criterion): {drift_flagged.height}\")\n",
        "\n",
        "top_6 = drift_flagged.head(6)[\"column\"].to_list()\n",
        "if top_6:\n",
        "    n_plot = len(top_6)\n",
        "    fig, axes = plt.subplots(2, 3, figsize=(15, 7))\n",
        "    axes = axes.flatten()\n",
        "    for i, col in enumerate(top_6):\n",
        "        ax = axes[i]\n",
        "        vals_e = early[col].drop_nulls().cast(pl.Float64).to_numpy()\n",
        "        vals_l = late[col].drop_nulls().cast(pl.Float64).to_numpy()\n",
        "        lo = np.nanpercentile(np.concatenate([vals_e, vals_l]), 1)\n",
        "        hi = np.nanpercentile(np.concatenate([vals_e, vals_l]), 99)\n",
        "        bins = np.linspace(lo, hi, 50)\n",
        "        ax.hist(vals_e, bins=bins, alpha=0.5, density=True, label=\"early\", color=\"#4C72B0\")\n",
        "        ax.hist(vals_l, bins=bins, alpha=0.5, density=True, label=\"late\", color=\"#DD8452\")\n",
        "        ax.set_title(col, fontsize=9)\n",
        "        ax.legend(fontsize=7)\n",
        "        ax.tick_params(labelsize=7)\n",
        "    for j in range(n_plot, len(axes)):\n",
        "        axes[j].set_visible(False)\n",
        "    fig.suptitle(\"Distribution Comparison: Early vs Late Weeks (top drifted features)\", fontsize=11)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## (d) Candidate Drift-Prone Features to Drop\n",
        "\n",
        "Features are flagged if **any** of these hold:\n",
        "- Normalised mean shift > 0.3\n",
        "- Normalised std shift > 0.3\n",
        "- Missing rate shift > 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "high_missing_cols = (\n",
        "    missing_df.filter(\n",
        "        (pl.col(\"table_group\") == \"static_0\") & (pl.col(\"missing_rate\") > 0.98)\n",
        "    )[\"column\"].to_list()\n",
        ")\n",
        "\n",
        "drift_prone_cols = drift_flagged[\"column\"].to_list()\n",
        "\n",
        "candidates_to_drop = sorted(set(drift_prone_cols + high_missing_cols))\n",
        "\n",
        "print(f\"Drift-prone features (static_0): {len(drift_prone_cols)}\")\n",
        "print(f\"High-missing features (>98%, static_0): {len(high_missing_cols)}\")\n",
        "print(f\"Combined unique candidates to drop: {len(candidates_to_drop)}\")\n",
        "print()\n",
        "print(\"Candidate features to drop:\")\n",
        "for col in candidates_to_drop:\n",
        "    reasons = []\n",
        "    if col in drift_prone_cols:\n",
        "        reasons.append(\"drift\")\n",
        "    if col in high_missing_cols:\n",
        "        reasons.append(\">98% missing\")\n",
        "    print(f\"  {col:45s} [{', '.join(reasons)}]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(\"DRIFT_PRONE_FEATURES = [\")\n",
        "for col in candidates_to_drop:\n",
        "    print(f'    \"{col}\",')\n",
        "print(\"]\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Feature Engineering — Date Columns & Domain Ratios"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test `handle_dates`\n",
        "\n",
        "Join base (with `date_decision`) to static_0 (which has date columns ending in `D`), then convert all dates to numeric features relative to the decision date."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged = base.join(static_0, on=\"case_id\", how=\"left\")\n",
        "\n",
        "date_d_cols = [c for c in merged.columns if c.endswith(\"D\") and c != \"date_decision\"]\n",
        "year_cols = [c for c in merged.columns if \"year\" in c.lower() and c not in date_d_cols and c != \"date_decision\"]\n",
        "\n",
        "print(f\"Columns ending in 'D' (excl. date_decision): {len(date_d_cols)}\")\n",
        "print(f\"  Examples: {date_d_cols[:5]}\")\n",
        "print(f\"Columns containing 'year': {len(year_cols)}\")\n",
        "if year_cols:\n",
        "    print(f\"  Examples: {year_cols[:5]}\")\n",
        "print(f\"\\nSample date_decision values:\\n{merged.select('date_decision').head(3)}\")\n",
        "if date_d_cols:\n",
        "    print(f\"\\nSample '{date_d_cols[0]}' values (before):\\n{merged.select(date_d_cols[0]).head(3)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "merged_dates = handle_dates(merged)\n",
        "\n",
        "print(f\"Shape before: {merged.shape}\")\n",
        "print(f\"Shape after:  {merged_dates.shape}\")\n",
        "print(f\"\\n'date_decision' dropped: {'date_decision' not in merged_dates.columns}\")\n",
        "print(f\"'MONTH' dropped:         {'MONTH' not in merged_dates.columns}\")\n",
        "\n",
        "transformed_d_cols = [c for c in date_d_cols if c in merged_dates.columns]\n",
        "if transformed_d_cols:\n",
        "    sample_col = transformed_d_cols[0]\n",
        "    print(f\"\\nSample '{sample_col}' values (after — years before decision):\")\n",
        "    print(merged_dates.select(sample_col).head(5))\n",
        "    print(f\"\\n'{sample_col}' dtype after: {merged_dates[sample_col].dtype}\")\n",
        "\n",
        "if year_cols:\n",
        "    sample_year = year_cols[0]\n",
        "    print(f\"\\nSample '{sample_year}' values (after — delta from decision year):\")\n",
        "    print(merged_dates.select(sample_year).head(5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Test `create_domain_ratios`\n",
        "\n",
        "Compute loan burden, disbursement, debt, and interest-rate ratios from static_0 columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "source_cols = [\"price_1097A\", \"annuity_780A\", \"disbursedcredamount_1113A\",\n",
        "               \"credamount_770A\", \"totaldebt_9A\", \"eir_270L\"]\n",
        "present = [c for c in source_cols if c in merged_dates.columns]\n",
        "missing = [c for c in source_cols if c not in merged_dates.columns]\n",
        "print(f\"Source columns present: {present}\")\n",
        "if missing:\n",
        "    print(f\"Source columns missing: {missing}\")\n",
        "\n",
        "merged_ratios = create_domain_ratios(merged_dates)\n",
        "\n",
        "ratio_cols = [\"loan_burden_ratio\", \"disbursed_credit_ratio\",\n",
        "              \"debt_credit_ratio\", \"eir_credit_ratio\"]\n",
        "new_cols = [c for c in ratio_cols if c in merged_ratios.columns]\n",
        "print(f\"\\nNew ratio columns created: {new_cols}\")\n",
        "print(f\"Shape before ratios: {merged_dates.shape}\")\n",
        "print(f\"Shape after ratios:  {merged_ratios.shape}\")\n",
        "\n",
        "if new_cols:\n",
        "    print(f\"\\nSample ratio values:\")\n",
        "    print(merged_ratios.select(new_cols).head(10))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "if new_cols:\n",
        "    n_plot = len(new_cols)\n",
        "    fig, axes = plt.subplots(1, n_plot, figsize=(5 * n_plot, 4))\n",
        "    if n_plot == 1:\n",
        "        axes = [axes]\n",
        "    for ax, col in zip(axes, new_cols):\n",
        "        vals = merged_ratios[col].drop_nulls().to_numpy()\n",
        "        lo, hi = np.nanpercentile(vals, [1, 99])\n",
        "        clipped = vals[(vals >= lo) & (vals <= hi)]\n",
        "        ax.hist(clipped, bins=50, color=\"#4C72B0\", edgecolor=\"none\", alpha=0.8)\n",
        "        ax.set_title(col, fontsize=10)\n",
        "        ax.set_ylabel(\"Count\")\n",
        "    fig.suptitle(\"Domain Ratio Feature Distributions (1st–99th pctl)\", fontsize=12)\n",
        "    fig.tight_layout()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Feature Engineering — Depth 1 Aggregations\n",
        "\n",
        "Load depth-1 tables, preprocess, aggregate by `case_id`, and join to the base table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DEPTH1_NAMES = [\n",
        "    \"applprev_1\",\n",
        "    \"credit_bureau_a_1\",\n",
        "    \"credit_bureau_b_1\",\n",
        "    \"person_1\",\n",
        "    \"tax_registry_a_1\",\n",
        "    \"tax_registry_b_1\",\n",
        "    \"tax_registry_c_1\",\n",
        "]\n",
        "\n",
        "depth1_tables = {}\n",
        "for name in DEPTH1_NAMES:\n",
        "    try:\n",
        "        df = load_table_group(DATA_PATH, name, split=\"train\")\n",
        "        df = preprocess_table(df)\n",
        "        depth1_tables[name] = df\n",
        "        print(f\"  {name:30s} {str(df.shape):>20s}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  {name:30s} {'NOT FOUND — skipped':>20s}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Filter `credit_bureau_a_1` to closed contracts\n",
        "\n",
        "Closed contracts populate closed-specific columns (e.g. `dateofcredend_353D`, `credlmt_228A`).\n",
        "Rows where these columns are **not null** represent closed contracts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "CLOSED_INDICATORS = [\n",
        "    \"dateofcredend_353D\",\n",
        "    \"dateofcredstart_739D\",\n",
        "    \"credlmt_228A\",\n",
        "    \"contractst_964M\",\n",
        "]\n",
        "\n",
        "if \"credit_bureau_a_1\" in depth1_tables:\n",
        "    cb_a_1 = depth1_tables[\"credit_bureau_a_1\"]\n",
        "    available = [c for c in CLOSED_INDICATORS if c in cb_a_1.columns]\n",
        "\n",
        "    if available:\n",
        "        filter_col = available[0]\n",
        "        before = cb_a_1.height\n",
        "        cb_a_1_closed = cb_a_1.filter(pl.col(filter_col).is_not_null())\n",
        "        depth1_tables[\"credit_bureau_a_1\"] = cb_a_1_closed\n",
        "        print(f\"Filtered credit_bureau_a_1 on '{filter_col}' is_not_null:\")\n",
        "        print(f\"  {before:,} → {cb_a_1_closed.height:,} rows\")\n",
        "    else:\n",
        "        print(f\"Warning: no closed-contract indicator found in columns.\")\n",
        "        print(f\"  Searched for: {CLOSED_INDICATORS}\")\n",
        "        print(f\"  Using all {cb_a_1.height:,} rows without filtering.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aggregate each depth-1 table and join to base"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "depth1_agg = {}\n",
        "for name, df in depth1_tables.items():\n",
        "    print(f\"\\n{'─'*60}\")\n",
        "    print(f\"  {name}  (input shape: {df.shape})\")\n",
        "    print(f\"{'─'*60}\")\n",
        "    depth1_agg[name] = aggregate_depth1(df)\n",
        "\n",
        "print(f\"\\n{'═'*60}\")\n",
        "print(\"Summary:\")\n",
        "for name, agg_df in depth1_agg.items():\n",
        "    print(f\"  {name:30s} → {agg_df.shape[1] - 1:>5,} features, {agg_df.height:>8,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "depth1_merged = base.clone()\n",
        "for name, agg_df in depth1_agg.items():\n",
        "    depth1_merged = depth1_merged.join(agg_df, on=\"case_id\", how=\"left\")\n",
        "    print(f\"  + {name:30s} → {depth1_merged.shape}\")\n",
        "\n",
        "total_d1_feats = depth1_merged.shape[1] - base.shape[1]\n",
        "print(f\"\\nBase columns:          {base.shape[1]}\")\n",
        "print(f\"New depth-1 features:  {total_d1_feats}\")\n",
        "print(f\"Final merged shape:    {depth1_merged.shape}\")\n",
        "print(f\"Memory:                {depth1_merged.estimated_size('mb'):.1f} MB\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Feature Engineering — Depth 2 Aggregations\n",
        "\n",
        "Two-pass aggregation: first by `(case_id, num_group1)`, then by `case_id`.\n",
        "Skip `credit_bureau_b_2` (very high missing rate)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DEPTH2_NAMES = [\n",
        "    \"applprev_2\",\n",
        "    \"person_2\",\n",
        "    \"credit_bureau_a_2\",\n",
        "    # credit_bureau_b_2 skipped — very high missing rate\n",
        "]\n",
        "\n",
        "depth2_tables = {}\n",
        "for name in DEPTH2_NAMES:\n",
        "    try:\n",
        "        df = load_table_group(DATA_PATH, name, split=\"train\")\n",
        "        df = preprocess_table(df)\n",
        "        depth2_tables[name] = df\n",
        "        print(f\"  {name:30s} {str(df.shape):>20s}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"  {name:30s} {'NOT FOUND — skipped':>20s}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "depth2_agg = {}\n",
        "for name, df in depth2_tables.items():\n",
        "    print(f\"\\n{'─'*60}\")\n",
        "    print(f\"  {name}  (input shape: {df.shape})\")\n",
        "    print(f\"{'─'*60}\")\n",
        "    depth2_agg[name] = aggregate_depth2(df)\n",
        "\n",
        "print(f\"\\n{'═'*60}\")\n",
        "print(\"Summary:\")\n",
        "for name, agg_df in depth2_agg.items():\n",
        "    print(f\"  {name:30s} → {agg_df.shape[1] - 1:>5,} features, {agg_df.height:>8,} rows\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Merge All Features (Depth 0 + 1 + 2)\n",
        "\n",
        "Combine depth-0 (base, static_0, static_cb_0), depth-1 aggregations, and depth-2 aggregations into a single training DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Depth-0 tables ──────────────────────────────────────────────\n",
        "train = base.join(static_0_processed, on=\"case_id\", how=\"left\")\n",
        "\n",
        "try:\n",
        "    static_cb_0 = load_table_group(DATA_PATH, \"static_cb_0\", split=\"train\")\n",
        "    static_cb_0 = preprocess_table(static_cb_0)\n",
        "    train = train.join(static_cb_0, on=\"case_id\", how=\"left\")\n",
        "    print(f\"+ static_cb_0          → {train.shape}\")\n",
        "except FileNotFoundError:\n",
        "    print(\"static_cb_0 not found — skipped\")\n",
        "\n",
        "train = handle_dates(train)\n",
        "train = create_domain_ratios(train)\n",
        "print(f\"Depth-0 (with dates & ratios): {train.shape}\")\n",
        "\n",
        "# ── Depth-1 aggregations ───────────────────────────────────────\n",
        "for name, agg_df in depth1_agg.items():\n",
        "    train = train.join(agg_df, on=\"case_id\", how=\"left\")\n",
        "print(f\"+ depth-1                    → {train.shape}\")\n",
        "\n",
        "# ── Depth-2 aggregations ───────────────────────────────────────\n",
        "for name, agg_df in depth2_agg.items():\n",
        "    train = train.join(agg_df, on=\"case_id\", how=\"left\")\n",
        "print(f\"+ depth-2                    → {train.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "info = get_table_info(train)\n",
        "n_numeric = sum(1 for c in train.columns if train[c].dtype in (pl.Float32, pl.Float64, pl.Int32, pl.Int64))\n",
        "n_string = sum(1 for c in train.columns if train[c].dtype in (pl.String, pl.Utf8, pl.Categorical))\n",
        "\n",
        "print(f\"Final merged DataFrame\")\n",
        "print(f\"  Shape:           {train.shape}\")\n",
        "print(f\"  Memory:          {info['estimated_memory_mb']:.1f} MB\")\n",
        "print(f\"  Numeric cols:    {n_numeric}\")\n",
        "print(f\"  String cols:     {n_string}\")\n",
        "print(f\"  >50% missing:    {len(info['columns_with_high_missing'])}\")\n",
        "print(f\"\\nDtype breakdown: {info['dtype_counts']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Post-Merge Feature Filtering\n",
        "\n",
        "1. Drop columns that are >95% correlated (keep the one with lower missing rate)\n",
        "2. Collapse rare categories (>200 unique → keep top 20, rest to null)\n",
        "3. Remove drift-prone features identified in EDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"Before filtering: {train.shape}\")\n",
        "\n",
        "train = drop_correlated_columns(train, threshold=0.95)\n",
        "train = collapse_rare_categories(train, max_unique=200, keep_top=20)\n",
        "train = remove_drift_features(train, candidates_to_drop)\n",
        "\n",
        "print(f\"\\nAfter filtering:  {train.shape}\")\n",
        "info = get_table_info(train)\n",
        "print(f\"Memory:           {info['estimated_memory_mb']:.1f} MB\")\n",
        "print(f\"Dtype breakdown:  {info['dtype_counts']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Build Test Features & Save\n",
        "\n",
        "Replicate the full feature pipeline on the test split, align columns with the\n",
        "filtered train set, then save both as parquet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# ── Depth-0 ─────────────────────────────────────────────────────\n",
        "test_base = load_table_group(DATA_PATH, \"base\", split=\"test\")\n",
        "test = test_base.clone()\n",
        "\n",
        "for tg in [\"static_0\", \"static_cb_0\"]:\n",
        "    try:\n",
        "        t = preprocess_table(load_table_group(DATA_PATH, tg, split=\"test\"))\n",
        "        test = test.join(t, on=\"case_id\", how=\"left\")\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "\n",
        "test = handle_dates(test)\n",
        "test = create_domain_ratios(test)\n",
        "print(f\"Test depth-0: {test.shape}\")\n",
        "\n",
        "# ── Depth-1 ─────────────────────────────────────────────────────\n",
        "for name in DEPTH1_NAMES:\n",
        "    try:\n",
        "        t = preprocess_table(load_table_group(DATA_PATH, name, split=\"test\"))\n",
        "        if name == \"credit_bureau_a_1\":\n",
        "            avail = [c for c in CLOSED_INDICATORS if c in t.columns]\n",
        "            if avail:\n",
        "                t = t.filter(pl.col(avail[0]).is_not_null())\n",
        "        test = test.join(aggregate_depth1(t), on=\"case_id\", how=\"left\")\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "print(f\"Test + depth-1: {test.shape}\")\n",
        "\n",
        "# ── Depth-2 ─────────────────────────────────────────────────────\n",
        "for name in DEPTH2_NAMES:\n",
        "    try:\n",
        "        t = preprocess_table(load_table_group(DATA_PATH, name, split=\"test\"))\n",
        "        test = test.join(aggregate_depth2(t), on=\"case_id\", how=\"left\")\n",
        "    except FileNotFoundError:\n",
        "        pass\n",
        "print(f\"Test + depth-2: {test.shape}\")\n",
        "\n",
        "# ── Post-merge filtering ───────────────────────────────────────\n",
        "test = collapse_rare_categories(test, max_unique=200, keep_top=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Align test columns with filtered train (minus target)\n",
        "train_feature_cols = [c for c in train.columns if c != \"target\"]\n",
        "present = [c for c in train_feature_cols if c in test.columns]\n",
        "missing_in_test = [c for c in train_feature_cols if c not in test.columns]\n",
        "\n",
        "if missing_in_test:\n",
        "    print(f\"Adding {len(missing_in_test)} null columns missing from test\")\n",
        "    test = test.with_columns([\n",
        "        pl.lit(None).cast(train[c].dtype).alias(c) for c in missing_in_test\n",
        "    ])\n",
        "\n",
        "test = test.select(train_feature_cols)\n",
        "print(f\"Train shape: {train.shape}\")\n",
        "print(f\"Test  shape: {test.shape}\")\n",
        "print(f\"Column match (excl. target): {list(test.columns) == train_feature_cols}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from pathlib import Path\n",
        "\n",
        "out_dir = Path(DATA_PATH) / \"processed\"\n",
        "out_dir.mkdir(exist_ok=True)\n",
        "\n",
        "train.write_parquet(out_dir / \"train_final.parquet\")\n",
        "test.write_parquet(out_dir / \"test_final.parquet\")\n",
        "\n",
        "print(f\"Saved to {out_dir.resolve()}\")\n",
        "print(f\"  train_final.parquet  {train.shape}  ({train.estimated_size('mb'):.1f} MB)\")\n",
        "print(f\"  test_final.parquet   {test.shape}  ({test.estimated_size('mb'):.1f} MB)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# CatBoost Baseline with StratifiedGroupKFold\n",
        "\n",
        "Train a CatBoost classifier using 5-fold CV where complete `WEEK_NUM` groups\n",
        "stay together (no week is split across folds). CatBoost handles categorical\n",
        "features natively — no encoding needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import StratifiedGroupKFold\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "META_COLS = {\"case_id\", \"target\", \"WEEK_NUM\"}\n",
        "feature_cols = [c for c in train.columns if c not in META_COLS]\n",
        "cat_cols = [c for c in feature_cols if train[c].dtype in (pl.String, pl.Utf8, pl.Categorical)]\n",
        "\n",
        "print(f\"Features:    {len(feature_cols)}\")\n",
        "print(f\"  numeric:   {len(feature_cols) - len(cat_cols)}\")\n",
        "print(f\"  categorical: {len(cat_cols)}\")\n",
        "\n",
        "train_pd = train.to_pandas()\n",
        "X = train_pd[feature_cols]\n",
        "y = train_pd[\"target\"].values\n",
        "week_num = train_pd[\"WEEK_NUM\"].values\n",
        "\n",
        "sgkf = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_preds = np.zeros(len(X))\n",
        "fold_results = []\n",
        "cb_models = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,}  \"\n",
        "          f\"val weeks {np.unique(week_num[val_idx]).tolist()[:6]}…)\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "    y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        iterations=1000,\n",
        "        learning_rate=0.05,\n",
        "        depth=6,\n",
        "        l2_leaf_reg=3.0,\n",
        "        random_seed=42 + fold,\n",
        "        eval_metric=\"AUC\",\n",
        "        cat_features=cat_cols,\n",
        "        allow_writing_files=False,\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=(X_val, y_val),\n",
        "        early_stopping_rounds=100,\n",
        "        verbose=200,\n",
        "    )\n",
        "\n",
        "    val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    oof_preds[val_idx] = val_pred\n",
        "\n",
        "    fold_auc = roc_auc_score(y_val, val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y_val, val_pred)\n",
        "\n",
        "    fold_results.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    cb_models.append(model)\n",
        "\n",
        "    print(f\"\\n  AUC:            {fold_auc:.6f}\")\n",
        "    print(f\"  Stability:      {fold_stab['stability_score']:.6f}\")\n",
        "    print(f\"  Mean Gini:      {fold_stab['mean_gini']:.6f}\")\n",
        "    print(f\"  Falling rate:   {fold_stab['falling_rate']:.6f}\")\n",
        "    print(f\"  Std residuals:  {fold_stab['std_residuals']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_auc = roc_auc_score(y, oof_preds)\n",
        "oof_stab = gini_stability(week_num, y, oof_preds)\n",
        "\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  Overall OOF Results (CatBoost)\")\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  AUC:            {oof_auc:.6f}\")\n",
        "print(f\"  Stability:      {oof_stab['stability_score']:.6f}\")\n",
        "print(f\"  Mean Gini:      {oof_stab['mean_gini']:.6f}\")\n",
        "print(f\"  Falling rate:   {oof_stab['falling_rate']:.6f}\")\n",
        "print(f\"  Std residuals:  {oof_stab['std_residuals']:.6f}\")\n",
        "print(f\"\\nPer-fold summary:\")\n",
        "for r in fold_results:\n",
        "    print(f\"  Fold {r['fold']}: AUC={r['auc']:.4f}  \"\n",
        "          f\"Stability={r['stability_score']:.4f}  \"\n",
        "          f\"Mean Gini={r['mean_gini']:.4f}\")\n",
        "\n",
        "ginis = oof_stab[\"weekly_ginis\"]\n",
        "x = np.arange(len(ginis))\n",
        "slope = oof_stab[\"slope\"]\n",
        "intercept = np.mean(ginis) - slope * np.mean(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 4))\n",
        "ax.plot(x, ginis, \"o-\", color=\"#4C72B0\", markersize=4, linewidth=1.2, label=\"weekly gini\")\n",
        "ax.plot(x, slope * x + intercept, \"--\", color=\"#DD8452\", linewidth=1.5,\n",
        "        label=f\"trend (slope={slope:.5f})\")\n",
        "ax.axhline(oof_stab[\"mean_gini\"], color=\"grey\", linestyle=\":\", linewidth=0.8,\n",
        "           label=f\"mean gini = {oof_stab['mean_gini']:.4f}\")\n",
        "ax.set_xlabel(\"Week Index\")\n",
        "ax.set_ylabel(\"Gini (2·AUC − 1)\")\n",
        "ax.set_title(f\"CatBoost OOF Weekly Gini  (stability = {oof_stab['stability_score']:.4f})\")\n",
        "ax.legend(fontsize=9)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import json\n",
        "\n",
        "artifacts_dir = Path(\"..\") / \"artifacts\"\n",
        "artifacts_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# OOF predictions\n",
        "oof_df = pl.DataFrame({\n",
        "    \"case_id\": train[\"case_id\"],\n",
        "    \"WEEK_NUM\": train[\"WEEK_NUM\"],\n",
        "    \"target\": train[\"target\"],\n",
        "    \"oof_score_catboost\": oof_preds,\n",
        "})\n",
        "oof_df.write_parquet(artifacts_dir / \"catboost_oof.parquet\")\n",
        "\n",
        "# Fold models\n",
        "for i, m in enumerate(cb_models):\n",
        "    m.save_model(str(artifacts_dir / f\"catboost_fold_{i}.cbm\"))\n",
        "\n",
        "# Scores\n",
        "with open(artifacts_dir / \"catboost_fold_scores.json\", \"w\") as f:\n",
        "    json.dump({\"fold_results\": fold_results, \"oof_auc\": oof_auc,\n",
        "               \"oof_stability\": oof_stab}, f, indent=2)\n",
        "\n",
        "print(f\"Artifacts saved to {artifacts_dir.resolve()}/\")\n",
        "print(f\"  catboost_oof.parquet          ({oof_df.shape})\")\n",
        "print(f\"  catboost_fold_0..4.cbm        (5 models)\")\n",
        "print(f\"  catboost_fold_scores.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## LightGBM — Same CV, Exclude High-Cardinality Categoricals\n",
        "\n",
        "LightGBM with native categorical support. To guard against overfitting, we drop\n",
        "string features with >200 unique values before training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import lightgbm as lgb\n",
        "\n",
        "cat_nunique = {c: X[c].nunique() for c in cat_cols}\n",
        "high_card_cats = {c for c, n in cat_nunique.items() if n > 200}\n",
        "lgb_cat_cols = [c for c in cat_cols if c not in high_card_cats]\n",
        "lgb_feature_cols = [c for c in feature_cols if c not in high_card_cats]\n",
        "\n",
        "print(f\"LightGBM features: {len(lgb_feature_cols)} \"\n",
        "      f\"({len(lgb_cat_cols)} cat, {len(lgb_feature_cols) - len(lgb_cat_cols)} num)\")\n",
        "print(f\"Excluded {len(high_card_cats)} high-cardinality categoricals (>200 uniques)\")\n",
        "\n",
        "X_lgb = X[lgb_feature_cols].copy()\n",
        "for col in lgb_cat_cols:\n",
        "    X_lgb[col] = X_lgb[col].astype(\"category\")\n",
        "\n",
        "test_pd = test.to_pandas()\n",
        "X_test_lgb = test_pd[lgb_feature_cols].copy()\n",
        "for col in lgb_cat_cols:\n",
        "    X_test_lgb[col] = X_test_lgb[col].astype(\"category\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_lgb = np.zeros(len(X))\n",
        "test_preds_lgb = np.zeros(len(test_pd))\n",
        "lgb_models = []\n",
        "lgb_fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,}  \"\n",
        "          f\"val weeks {np.unique(week_num[val_idx]).tolist()[:6]}…)\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    X_tr, X_val = X_lgb.iloc[train_idx], X_lgb.iloc[val_idx]\n",
        "    y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        num_leaves=64,\n",
        "        reg_lambda=3.0,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        random_state=42 + fold,\n",
        "        verbose=-1,\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        X_tr, y_tr,\n",
        "        eval_set=[(X_val, y_val)],\n",
        "        eval_metric=\"auc\",\n",
        "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(200)],\n",
        "    )\n",
        "\n",
        "    val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    oof_lgb[val_idx] = val_pred\n",
        "    test_preds_lgb += model.predict_proba(X_test_lgb)[:, 1] / 5\n",
        "\n",
        "    fold_auc = roc_auc_score(y_val, val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y_val, val_pred)\n",
        "\n",
        "    lgb_fold_results.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    lgb_models.append(model)\n",
        "\n",
        "    print(f\"\\n  AUC:            {fold_auc:.6f}\")\n",
        "    print(f\"  Stability:      {fold_stab['stability_score']:.6f}\")\n",
        "    print(f\"  Mean Gini:      {fold_stab['mean_gini']:.6f}\")\n",
        "    print(f\"  Falling rate:   {fold_stab['falling_rate']:.6f}\")\n",
        "    print(f\"  Std residuals:  {fold_stab['std_residuals']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_auc_lgb = roc_auc_score(y, oof_lgb)\n",
        "oof_stab_lgb = gini_stability(week_num, y, oof_lgb)\n",
        "\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  Overall OOF Results (LightGBM)\")\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  AUC:            {oof_auc_lgb:.6f}\")\n",
        "print(f\"  Stability:      {oof_stab_lgb['stability_score']:.6f}\")\n",
        "print(f\"  Mean Gini:      {oof_stab_lgb['mean_gini']:.6f}\")\n",
        "print(f\"  Falling rate:   {oof_stab_lgb['falling_rate']:.6f}\")\n",
        "print(f\"  Std residuals:  {oof_stab_lgb['std_residuals']:.6f}\")\n",
        "print(f\"\\nPer-fold summary:\")\n",
        "for r in lgb_fold_results:\n",
        "    print(f\"  Fold {r['fold']}: AUC={r['auc']:.4f}  \"\n",
        "          f\"Stability={r['stability_score']:.4f}  \"\n",
        "          f\"Mean Gini={r['mean_gini']:.4f}\")\n",
        "\n",
        "ginis = oof_stab_lgb[\"weekly_ginis\"]\n",
        "x = np.arange(len(ginis))\n",
        "slope = oof_stab_lgb[\"slope\"]\n",
        "intercept = np.mean(ginis) - slope * np.mean(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 4))\n",
        "ax.plot(x, ginis, \"o-\", color=\"#4C72B0\", markersize=4, linewidth=1.2, label=\"weekly gini\")\n",
        "ax.plot(x, slope * x + intercept, \"--\", color=\"#DD8452\", linewidth=1.5,\n",
        "        label=f\"trend (slope={slope:.5f})\")\n",
        "ax.axhline(oof_stab_lgb[\"mean_gini\"], color=\"grey\", linestyle=\":\", linewidth=0.8,\n",
        "           label=f\"mean gini = {oof_stab_lgb['mean_gini']:.4f}\")\n",
        "ax.set_xlabel(\"Week Index\")\n",
        "ax.set_ylabel(\"Gini (2·AUC − 1)\")\n",
        "ax.set_title(f\"LightGBM OOF Weekly Gini  (stability = {oof_stab_lgb['stability_score']:.4f})\")\n",
        "ax.legend(fontsize=9)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "lgb_oof_df = pl.DataFrame({\n",
        "    \"case_id\": train[\"case_id\"],\n",
        "    \"WEEK_NUM\": train[\"WEEK_NUM\"],\n",
        "    \"target\": train[\"target\"],\n",
        "    \"oof_score_lgb\": oof_lgb,\n",
        "})\n",
        "lgb_oof_df.write_parquet(artifacts_dir / \"lgb_oof.parquet\")\n",
        "\n",
        "lgb_test_df = pl.DataFrame({\n",
        "    \"case_id\": test[\"case_id\"],\n",
        "    \"test_score_lgb\": test_preds_lgb,\n",
        "})\n",
        "lgb_test_df.write_parquet(artifacts_dir / \"lgb_test_preds.parquet\")\n",
        "\n",
        "for i, m in enumerate(lgb_models):\n",
        "    m.booster_.save_model(str(artifacts_dir / f\"lgb_fold_{i}.txt\"))\n",
        "\n",
        "with open(artifacts_dir / \"lgb_fold_scores.json\", \"w\") as f:\n",
        "    json.dump({\"fold_results\": lgb_fold_results, \"oof_auc\": oof_auc_lgb,\n",
        "               \"oof_stability\": oof_stab_lgb}, f, indent=2)\n",
        "\n",
        "print(f\"LightGBM artifacts saved to {artifacts_dir.resolve()}/\")\n",
        "print(f\"  lgb_oof.parquet             ({lgb_oof_df.shape})\")\n",
        "print(f\"  lgb_test_preds.parquet      ({lgb_test_df.shape})\")\n",
        "print(f\"  lgb_fold_0..4.txt           (5 models)\")\n",
        "print(f\"  lgb_fold_scores.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## XGBoost — Fold-Safe CatBoost (Target) Encoding\n",
        "\n",
        "XGBoost requires numeric input, so we encode categoricals with CatBoostEncoder.\n",
        "**Critically**, the encoder is fit only on each fold's training split, never on\n",
        "the full dataset. Validation and test sets are transformed with the fold-specific\n",
        "encoder to prevent any target leakage."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from category_encoders import CatBoostEncoder\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_feature_cols = lgb_feature_cols\n",
        "\n",
        "oof_xgb = np.zeros(len(X))\n",
        "test_preds_xgb = np.zeros(len(test_pd))\n",
        "xgb_models = []\n",
        "xgb_encoders = []\n",
        "xgb_fold_results = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,}  \"\n",
        "          f\"val weeks {np.unique(week_num[val_idx]).tolist()[:6]}…)\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    X_tr = X[xgb_feature_cols].iloc[train_idx].copy()\n",
        "    X_val = X[xgb_feature_cols].iloc[val_idx].copy()\n",
        "    y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "    # Fold-safe encoding: fit ONLY on this fold's training split\n",
        "    encoder = CatBoostEncoder(cols=lgb_cat_cols, random_state=42 + fold)\n",
        "    X_tr[lgb_cat_cols] = encoder.fit_transform(X_tr[lgb_cat_cols], y_tr)\n",
        "    X_val[lgb_cat_cols] = encoder.transform(X_val[lgb_cat_cols])\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        learning_rate=0.05,\n",
        "        max_depth=6,\n",
        "        reg_lambda=3.0,\n",
        "        colsample_bytree=0.8,\n",
        "        subsample=0.8,\n",
        "        random_state=42 + fold,\n",
        "        eval_metric=\"auc\",\n",
        "        tree_method=\"hist\",\n",
        "        early_stopping_rounds=100,\n",
        "        verbosity=0,\n",
        "    )\n",
        "    model.fit(X_tr, y_tr, eval_set=[(X_val, y_val)], verbose=200)\n",
        "\n",
        "    val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    oof_xgb[val_idx] = val_pred\n",
        "\n",
        "    # Encode test with THIS fold's encoder — never a full-data encoder\n",
        "    X_test_fold = test_pd[xgb_feature_cols].copy()\n",
        "    X_test_fold[lgb_cat_cols] = encoder.transform(X_test_fold[lgb_cat_cols])\n",
        "    test_preds_xgb += model.predict_proba(X_test_fold)[:, 1] / 5\n",
        "\n",
        "    fold_auc = roc_auc_score(y_val, val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y_val, val_pred)\n",
        "\n",
        "    xgb_fold_results.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    xgb_models.append(model)\n",
        "    xgb_encoders.append(encoder)\n",
        "\n",
        "    print(f\"\\n  AUC:            {fold_auc:.6f}\")\n",
        "    print(f\"  Stability:      {fold_stab['stability_score']:.6f}\")\n",
        "    print(f\"  Mean Gini:      {fold_stab['mean_gini']:.6f}\")\n",
        "    print(f\"  Falling rate:   {fold_stab['falling_rate']:.6f}\")\n",
        "    print(f\"  Std residuals:  {fold_stab['std_residuals']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_auc_xgb = roc_auc_score(y, oof_xgb)\n",
        "oof_stab_xgb = gini_stability(week_num, y, oof_xgb)\n",
        "\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  Overall OOF Results (XGBoost)\")\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  AUC:            {oof_auc_xgb:.6f}\")\n",
        "print(f\"  Stability:      {oof_stab_xgb['stability_score']:.6f}\")\n",
        "print(f\"  Mean Gini:      {oof_stab_xgb['mean_gini']:.6f}\")\n",
        "print(f\"  Falling rate:   {oof_stab_xgb['falling_rate']:.6f}\")\n",
        "print(f\"  Std residuals:  {oof_stab_xgb['std_residuals']:.6f}\")\n",
        "print(f\"\\nPer-fold summary:\")\n",
        "for r in xgb_fold_results:\n",
        "    print(f\"  Fold {r['fold']}: AUC={r['auc']:.4f}  \"\n",
        "          f\"Stability={r['stability_score']:.4f}  \"\n",
        "          f\"Mean Gini={r['mean_gini']:.4f}\")\n",
        "\n",
        "ginis = oof_stab_xgb[\"weekly_ginis\"]\n",
        "x = np.arange(len(ginis))\n",
        "slope = oof_stab_xgb[\"slope\"]\n",
        "intercept = np.mean(ginis) - slope * np.mean(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 4))\n",
        "ax.plot(x, ginis, \"o-\", color=\"#4C72B0\", markersize=4, linewidth=1.2, label=\"weekly gini\")\n",
        "ax.plot(x, slope * x + intercept, \"--\", color=\"#DD8452\", linewidth=1.5,\n",
        "        label=f\"trend (slope={slope:.5f})\")\n",
        "ax.axhline(oof_stab_xgb[\"mean_gini\"], color=\"grey\", linestyle=\":\", linewidth=0.8,\n",
        "           label=f\"mean gini = {oof_stab_xgb['mean_gini']:.4f}\")\n",
        "ax.set_xlabel(\"Week Index\")\n",
        "ax.set_ylabel(\"Gini (2·AUC − 1)\")\n",
        "ax.set_title(f\"XGBoost OOF Weekly Gini  (stability = {oof_stab_xgb['stability_score']:.4f})\")\n",
        "ax.legend(fontsize=9)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# XGBoost artifacts\n",
        "xgb_oof_df = pl.DataFrame({\n",
        "    \"case_id\": train[\"case_id\"],\n",
        "    \"WEEK_NUM\": train[\"WEEK_NUM\"],\n",
        "    \"target\": train[\"target\"],\n",
        "    \"oof_score_xgb\": oof_xgb,\n",
        "})\n",
        "xgb_oof_df.write_parquet(artifacts_dir / \"xgb_oof.parquet\")\n",
        "\n",
        "xgb_test_df = pl.DataFrame({\n",
        "    \"case_id\": test[\"case_id\"],\n",
        "    \"test_score_xgb\": test_preds_xgb,\n",
        "})\n",
        "xgb_test_df.write_parquet(artifacts_dir / \"xgb_test_preds.parquet\")\n",
        "\n",
        "for i, m in enumerate(xgb_models):\n",
        "    m.save_model(str(artifacts_dir / f\"xgb_fold_{i}.json\"))\n",
        "\n",
        "with open(artifacts_dir / \"xgb_fold_scores.json\", \"w\") as f:\n",
        "    json.dump({\"fold_results\": xgb_fold_results, \"oof_auc\": oof_auc_xgb,\n",
        "               \"oof_stability\": oof_stab_xgb}, f, indent=2)\n",
        "\n",
        "# CatBoost test predictions (generated with already-saved fold models)\n",
        "test_preds_cb = np.zeros(len(test_pd))\n",
        "for m in cb_models:\n",
        "    test_preds_cb += m.predict_proba(test_pd[feature_cols])[:, 1] / 5\n",
        "\n",
        "cb_test_df = pl.DataFrame({\n",
        "    \"case_id\": test[\"case_id\"],\n",
        "    \"test_score_catboost\": test_preds_cb,\n",
        "})\n",
        "cb_test_df.write_parquet(artifacts_dir / \"catboost_test_preds.parquet\")\n",
        "\n",
        "print(f\"XGBoost artifacts saved to {artifacts_dir.resolve()}/\")\n",
        "print(f\"  xgb_oof.parquet             ({xgb_oof_df.shape})\")\n",
        "print(f\"  xgb_test_preds.parquet      ({xgb_test_df.shape})\")\n",
        "print(f\"  xgb_fold_0..4.json          (5 models)\")\n",
        "print(f\"  xgb_fold_scores.json\")\n",
        "print(f\"\\nCatBoost test predictions:\")\n",
        "print(f\"  catboost_test_preds.parquet  ({cb_test_df.shape})\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(f\"{'═'*70}\")\n",
        "print(f\"  Model Comparison — OOF Metrics\")\n",
        "print(f\"{'═'*70}\")\n",
        "print(f\"{'Model':<12} {'AUC':>10} {'Stability':>12} {'Mean Gini':>12} \"\n",
        "      f\"{'Falling':>10} {'Std Resid':>12}\")\n",
        "print(f\"{'─'*70}\")\n",
        "for name, auc_val, stab in [\n",
        "    (\"CatBoost\",  oof_auc,     oof_stab),\n",
        "    (\"LightGBM\",  oof_auc_lgb, oof_stab_lgb),\n",
        "    (\"XGBoost\",   oof_auc_xgb, oof_stab_xgb),\n",
        "]:\n",
        "    print(f\"{name:<12} {auc_val:>10.6f} {stab['stability_score']:>12.6f} \"\n",
        "          f\"{stab['mean_gini']:>12.6f} {stab['falling_rate']:>10.6f} \"\n",
        "          f\"{stab['std_residuals']:>12.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Retrain Tuned Models & Regenerate OOF\n",
        "\n",
        "Load Optuna-tuned hyper-parameters from `best_params.json`, retrain all three\n",
        "models under the **identical CV protocol**, and regenerate fresh OOF + averaged\n",
        "test predictions.  Persist model files, feature lists, categorical columns, and\n",
        "XGBoost encoder configs so train/inference are fully reproducible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "with open(artifacts_dir / \"best_params.json\") as f:\n",
        "    tuning_results = json.load(f)\n",
        "\n",
        "cb_best = tuning_results[\"catboost\"][\"best_params\"]\n",
        "lgb_best = tuning_results[\"lightgbm\"][\"best_params\"]\n",
        "xgb_best = tuning_results[\"xgboost\"][\"best_params\"]\n",
        "\n",
        "print(\"Loaded tuned hyper-parameters\\n\")\n",
        "for name, params in [(\"CatBoost\", cb_best), (\"LightGBM\", lgb_best), (\"XGBoost\", xgb_best)]:\n",
        "    print(f\"  {name}:\")\n",
        "    for k, v in params.items():\n",
        "        print(f\"    {k:<22} {v}\")\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_cb_t = np.zeros(len(X))\n",
        "test_cb_t = np.zeros(len(test_pd))\n",
        "cb_t_models = []\n",
        "cb_t_folds = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  CatBoost (tuned) — Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,})\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    model = CatBoostClassifier(\n",
        "        iterations=1000,\n",
        "        **cb_best,\n",
        "        random_seed=42 + fold,\n",
        "        eval_metric=\"AUC\",\n",
        "        cat_features=cat_cols,\n",
        "        allow_writing_files=False,\n",
        "    )\n",
        "    model.fit(\n",
        "        X.iloc[train_idx], y[train_idx],\n",
        "        eval_set=(X.iloc[val_idx], y[val_idx]),\n",
        "        early_stopping_rounds=100,\n",
        "        verbose=200,\n",
        "    )\n",
        "\n",
        "    val_pred = model.predict_proba(X.iloc[val_idx])[:, 1]\n",
        "    oof_cb_t[val_idx] = val_pred\n",
        "    test_cb_t += model.predict_proba(test_pd[feature_cols])[:, 1] / 5\n",
        "\n",
        "    fold_auc = roc_auc_score(y[val_idx], val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y[val_idx], val_pred)\n",
        "    cb_t_folds.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    cb_t_models.append(model)\n",
        "\n",
        "    print(f\"  AUC: {fold_auc:.6f}  Stability: {fold_stab['stability_score']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_lgb_t = np.zeros(len(X))\n",
        "test_lgb_t = np.zeros(len(test_pd))\n",
        "lgb_t_models = []\n",
        "lgb_t_folds = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  LightGBM (tuned) — Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,})\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    model = lgb.LGBMClassifier(\n",
        "        n_estimators=1000,\n",
        "        **lgb_best,\n",
        "        random_state=42 + fold,\n",
        "        verbose=-1,\n",
        "    )\n",
        "    model.fit(\n",
        "        X_lgb.iloc[train_idx], y[train_idx],\n",
        "        eval_set=[(X_lgb.iloc[val_idx], y[val_idx])],\n",
        "        eval_metric=\"auc\",\n",
        "        callbacks=[lgb.early_stopping(100), lgb.log_evaluation(200)],\n",
        "    )\n",
        "\n",
        "    val_pred = model.predict_proba(X_lgb.iloc[val_idx])[:, 1]\n",
        "    oof_lgb_t[val_idx] = val_pred\n",
        "    test_lgb_t += model.predict_proba(X_test_lgb)[:, 1] / 5\n",
        "\n",
        "    fold_auc = roc_auc_score(y[val_idx], val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y[val_idx], val_pred)\n",
        "    lgb_t_folds.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    lgb_t_models.append(model)\n",
        "\n",
        "    print(f\"  AUC: {fold_auc:.6f}  Stability: {fold_stab['stability_score']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "oof_xgb_t = np.zeros(len(X))\n",
        "test_xgb_t = np.zeros(len(test_pd))\n",
        "xgb_t_models = []\n",
        "xgb_t_encoders = []\n",
        "xgb_t_folds = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(sgkf.split(X, y, week_num)):\n",
        "    print(f\"\\n{'═'*60}\")\n",
        "    print(f\"  XGBoost (tuned) — Fold {fold + 1} / 5   \"\n",
        "          f\"(train {len(train_idx):,}  val {len(val_idx):,})\")\n",
        "    print(f\"{'═'*60}\")\n",
        "\n",
        "    X_tr = X[lgb_feature_cols].iloc[train_idx].copy()\n",
        "    X_val = X[lgb_feature_cols].iloc[val_idx].copy()\n",
        "\n",
        "    encoder = CatBoostEncoder(cols=lgb_cat_cols, random_state=42 + fold)\n",
        "    X_tr[lgb_cat_cols] = encoder.fit_transform(X_tr[lgb_cat_cols], y[train_idx])\n",
        "    X_val[lgb_cat_cols] = encoder.transform(X_val[lgb_cat_cols])\n",
        "\n",
        "    model = XGBClassifier(\n",
        "        n_estimators=1000,\n",
        "        **xgb_best,\n",
        "        random_state=42 + fold,\n",
        "        eval_metric=\"auc\",\n",
        "        tree_method=\"hist\",\n",
        "        early_stopping_rounds=100,\n",
        "        verbosity=0,\n",
        "    )\n",
        "    model.fit(X_tr, y[train_idx], eval_set=[(X_val, y[val_idx])], verbose=200)\n",
        "\n",
        "    val_pred = model.predict_proba(X_val)[:, 1]\n",
        "    oof_xgb_t[val_idx] = val_pred\n",
        "\n",
        "    X_test_fold = test_pd[lgb_feature_cols].copy()\n",
        "    X_test_fold[lgb_cat_cols] = encoder.transform(X_test_fold[lgb_cat_cols])\n",
        "    test_xgb_t += model.predict_proba(X_test_fold)[:, 1] / 5\n",
        "\n",
        "    fold_auc = roc_auc_score(y[val_idx], val_pred)\n",
        "    fold_stab = gini_stability(week_num[val_idx], y[val_idx], val_pred)\n",
        "    xgb_t_folds.append({\"fold\": fold + 1, \"auc\": fold_auc, **fold_stab})\n",
        "    xgb_t_models.append(model)\n",
        "    xgb_t_encoders.append(encoder)\n",
        "\n",
        "    print(f\"  AUC: {fold_auc:.6f}  Stability: {fold_stab['stability_score']:.6f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "auc_cb_t  = roc_auc_score(y, oof_cb_t)\n",
        "stab_cb_t = gini_stability(week_num, y, oof_cb_t)\n",
        "\n",
        "auc_lgb_t  = roc_auc_score(y, oof_lgb_t)\n",
        "stab_lgb_t = gini_stability(week_num, y, oof_lgb_t)\n",
        "\n",
        "auc_xgb_t  = roc_auc_score(y, oof_xgb_t)\n",
        "stab_xgb_t = gini_stability(week_num, y, oof_xgb_t)\n",
        "\n",
        "print(f\"{'═'*76}\")\n",
        "print(f\"  Baseline vs Tuned — OOF Comparison\")\n",
        "print(f\"{'═'*76}\")\n",
        "print(f\"{'Model':<11} {'Base AUC':>10} {'Tuned AUC':>11} {'ΔAUC':>8}\"\n",
        "      f\"  {'Base Stab':>11} {'Tuned Stab':>11} {'ΔStab':>8}\")\n",
        "print(f\"{'─'*76}\")\n",
        "for name, b_auc, b_stab, t_auc, t_stab in [\n",
        "    (\"CatBoost\",  oof_auc,     oof_stab,     auc_cb_t,  stab_cb_t),\n",
        "    (\"LightGBM\",  oof_auc_lgb, oof_stab_lgb, auc_lgb_t, stab_lgb_t),\n",
        "    (\"XGBoost\",   oof_auc_xgb, oof_stab_xgb, auc_xgb_t, stab_xgb_t),\n",
        "]:\n",
        "    d_auc  = t_auc - b_auc\n",
        "    d_stab = t_stab[\"stability_score\"] - b_stab[\"stability_score\"]\n",
        "    print(f\"{name:<11} {b_auc:>10.6f} {t_auc:>11.6f} {d_auc:>+8.4f}\"\n",
        "          f\"  {b_stab['stability_score']:>11.6f}\"\n",
        "          f\" {t_stab['stability_score']:>11.6f} {d_stab:>+8.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import pickle\n",
        "\n",
        "tuned_dir = artifacts_dir / \"tuned\"\n",
        "tuned_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# ── Combined OOF predictions ──────────────────────────────────\n",
        "oof_all = pl.DataFrame({\n",
        "    \"case_id\": train[\"case_id\"],\n",
        "    \"WEEK_NUM\": train[\"WEEK_NUM\"],\n",
        "    \"target\": train[\"target\"],\n",
        "    \"oof_catboost\": oof_cb_t,\n",
        "    \"oof_lightgbm\": oof_lgb_t,\n",
        "    \"oof_xgboost\": oof_xgb_t,\n",
        "})\n",
        "oof_all.write_parquet(tuned_dir / \"tuned_oof.parquet\")\n",
        "\n",
        "# ── Combined test predictions (fold-averaged) ─────────────────\n",
        "test_all = pl.DataFrame({\n",
        "    \"case_id\": test[\"case_id\"],\n",
        "    \"test_catboost\": test_cb_t,\n",
        "    \"test_lightgbm\": test_lgb_t,\n",
        "    \"test_xgboost\": test_xgb_t,\n",
        "})\n",
        "test_all.write_parquet(tuned_dir / \"tuned_test_preds.parquet\")\n",
        "\n",
        "# ── Fold models ───────────────────────────────────────────────\n",
        "for i, m in enumerate(cb_t_models):\n",
        "    m.save_model(str(tuned_dir / f\"catboost_fold_{i}.cbm\"))\n",
        "for i, m in enumerate(lgb_t_models):\n",
        "    m.booster_.save_model(str(tuned_dir / f\"lgb_fold_{i}.txt\"))\n",
        "for i, m in enumerate(xgb_t_models):\n",
        "    m.save_model(str(tuned_dir / f\"xgb_fold_{i}.json\"))\n",
        "\n",
        "# ── XGBoost per-fold encoders (needed for consistent inference) ─\n",
        "for i, enc in enumerate(xgb_t_encoders):\n",
        "    with open(tuned_dir / f\"xgb_encoder_fold_{i}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(enc, f)\n",
        "\n",
        "# ── Feature lists & categorical columns ───────────────────────\n",
        "feature_config = {\n",
        "    \"catboost\": {\n",
        "        \"feature_cols\": feature_cols,\n",
        "        \"cat_cols\": cat_cols,\n",
        "    },\n",
        "    \"lightgbm\": {\n",
        "        \"feature_cols\": lgb_feature_cols,\n",
        "        \"cat_cols\": lgb_cat_cols,\n",
        "    },\n",
        "    \"xgboost\": {\n",
        "        \"feature_cols\": lgb_feature_cols,\n",
        "        \"cat_cols\": lgb_cat_cols,\n",
        "    },\n",
        "}\n",
        "with open(tuned_dir / \"feature_config.json\", \"w\") as f:\n",
        "    json.dump(feature_config, f, indent=2)\n",
        "\n",
        "# ── Scores summary ────────────────────────────────────────────\n",
        "scores = {\n",
        "    \"catboost\": {\n",
        "        \"oof_auc\": auc_cb_t, \"oof_stability\": stab_cb_t,\n",
        "        \"fold_results\": cb_t_folds,\n",
        "    },\n",
        "    \"lightgbm\": {\n",
        "        \"oof_auc\": auc_lgb_t, \"oof_stability\": stab_lgb_t,\n",
        "        \"fold_results\": lgb_t_folds,\n",
        "    },\n",
        "    \"xgboost\": {\n",
        "        \"oof_auc\": auc_xgb_t, \"oof_stability\": stab_xgb_t,\n",
        "        \"fold_results\": xgb_t_folds,\n",
        "    },\n",
        "}\n",
        "with open(tuned_dir / \"tuned_scores.json\", \"w\") as f:\n",
        "    json.dump(scores, f, indent=2)\n",
        "\n",
        "print(f\"Tuned artifacts saved to {tuned_dir.resolve()}/\")\n",
        "print(f\"  tuned_oof.parquet           ({oof_all.shape})\")\n",
        "print(f\"  tuned_test_preds.parquet    ({test_all.shape})\")\n",
        "print(f\"  catboost_fold_0..4.cbm      (5 models)\")\n",
        "print(f\"  lgb_fold_0..4.txt           (5 models)\")\n",
        "print(f\"  xgb_fold_0..4.json          (5 models)\")\n",
        "print(f\"  xgb_encoder_fold_0..4.pkl   (5 encoders)\")\n",
        "print(f\"  feature_config.json\")\n",
        "print(f\"  tuned_scores.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Stacking Ensemble — Calibrated Ridge Meta-Learner\n",
        "\n",
        "Stack the three tuned base-model OOF predictions through\n",
        "`CalibratedClassifierCV(RidgeClassifier)`.  Random seed averaging (3 seeds)\n",
        "varies the internal calibration CV splits and averages predictions to reduce\n",
        "meta-learner variance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from src.ensemble import build_stacking_ensemble\n",
        "\n",
        "oof_stack = np.column_stack([oof_cb_t, oof_lgb_t, oof_xgb_t])\n",
        "test_stack = np.column_stack([test_cb_t, test_lgb_t, test_xgb_t])\n",
        "\n",
        "print(f\"Stack matrix: OOF {oof_stack.shape}, test {test_stack.shape}\\n\")\n",
        "\n",
        "ensemble = build_stacking_ensemble(\n",
        "    oof_stack, y, week_num, test_stack,\n",
        "    seeds=[42, 123, 456],\n",
        "    alpha=1.0,\n",
        "    n_splits=5,\n",
        "    cv_seed=42,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stab_ens = ensemble[\"oof_stability\"]\n",
        "\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"  Ensemble vs Individual Tuned Models\")\n",
        "print(f\"{'═'*60}\")\n",
        "print(f\"{'Model':<15} {'AUC':>10} {'Stability':>12}\")\n",
        "print(f\"{'─'*60}\")\n",
        "for name, auc_val, stab_dict in [\n",
        "    (\"CatBoost\",   auc_cb_t,            stab_cb_t),\n",
        "    (\"LightGBM\",   auc_lgb_t,           stab_lgb_t),\n",
        "    (\"XGBoost\",    auc_xgb_t,           stab_xgb_t),\n",
        "    (\"Ensemble\",   ensemble[\"oof_auc\"], stab_ens),\n",
        "]:\n",
        "    print(f\"{name:<15} {auc_val:>10.6f} {stab_dict['stability_score']:>12.6f}\")\n",
        "\n",
        "# Weekly Gini plot\n",
        "ginis = stab_ens[\"weekly_ginis\"]\n",
        "x = np.arange(len(ginis))\n",
        "slope = stab_ens[\"slope\"]\n",
        "intercept = np.mean(ginis) - slope * np.mean(x)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 4))\n",
        "ax.plot(x, ginis, \"o-\", color=\"#4C72B0\", markersize=4, linewidth=1.2, label=\"weekly gini\")\n",
        "ax.plot(x, slope * x + intercept, \"--\", color=\"#DD8452\", linewidth=1.5,\n",
        "        label=f\"trend (slope={slope:.5f})\")\n",
        "ax.axhline(stab_ens[\"mean_gini\"], color=\"grey\", linestyle=\":\", linewidth=0.8,\n",
        "           label=f\"mean gini = {stab_ens['mean_gini']:.4f}\")\n",
        "ax.set_xlabel(\"Week Index\")\n",
        "ax.set_ylabel(\"Gini (2·AUC − 1)\")\n",
        "ax.set_title(f\"Stacking Ensemble OOF Weekly Gini  \"\n",
        "             f\"(stability = {stab_ens['stability_score']:.4f})\")\n",
        "ax.legend(fontsize=9)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ens_oof = pl.DataFrame({\n",
        "    \"case_id\": train[\"case_id\"],\n",
        "    \"WEEK_NUM\": train[\"WEEK_NUM\"],\n",
        "    \"target\": train[\"target\"],\n",
        "    \"oof_ensemble\": ensemble[\"oof_preds\"],\n",
        "})\n",
        "ens_oof.write_parquet(tuned_dir / \"ensemble_oof.parquet\")\n",
        "\n",
        "ens_test = pl.DataFrame({\n",
        "    \"case_id\": test[\"case_id\"],\n",
        "    \"test_ensemble\": ensemble[\"test_preds\"],\n",
        "})\n",
        "ens_test.write_parquet(tuned_dir / \"ensemble_test_preds.parquet\")\n",
        "\n",
        "for i, ml in enumerate(ensemble[\"meta_learners\"]):\n",
        "    with open(tuned_dir / f\"meta_learner_seed_{i}.pkl\", \"wb\") as f:\n",
        "        pickle.dump(ml, f)\n",
        "\n",
        "with open(tuned_dir / \"ensemble_scores.json\", \"w\") as f:\n",
        "    json.dump({\n",
        "        \"oof_auc\": ensemble[\"oof_auc\"],\n",
        "        \"oof_stability\": ensemble[\"oof_stability\"],\n",
        "        \"seeds\": [42, 123, 456],\n",
        "        \"alpha\": 1.0,\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"Ensemble artifacts saved to {tuned_dir.resolve()}/\")\n",
        "print(f\"  ensemble_oof.parquet          ({ens_oof.shape})\")\n",
        "print(f\"  ensemble_test_preds.parquet   ({ens_test.shape})\")\n",
        "print(f\"  meta_learner_seed_0..2.pkl    (3 meta-learners)\")\n",
        "print(f\"  ensemble_scores.json\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Pseudo-Future Holdout & Runtime Profiling\n",
        "\n",
        "Train on the **earliest 80 % of weeks** and validate on the **most recent 20 %**\n",
        "to simulate real-world temporal drift that the model will face after deployment.\n",
        "Every stage is timed so we can project total Kaggle CPU runtime and trim\n",
        "expensive steps if the budget exceeds 12 hours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import time\n",
        "\n",
        "unique_weeks = np.sort(np.unique(week_num))\n",
        "n_weeks = len(unique_weeks)\n",
        "cutoff_idx = int(n_weeks * 0.8)\n",
        "cutoff_week = unique_weeks[cutoff_idx - 1]\n",
        "\n",
        "ho_train_mask = week_num <= cutoff_week\n",
        "ho_val_mask   = week_num > cutoff_week\n",
        "ho_train_idx  = np.where(ho_train_mask)[0]\n",
        "ho_val_idx    = np.where(ho_val_mask)[0]\n",
        "\n",
        "print(f\"Unique weeks:  {n_weeks}\")\n",
        "print(f\"Train weeks:   {unique_weeks[0]} – {cutoff_week}  \"\n",
        "      f\"({cutoff_idx} weeks, {len(ho_train_idx):,} rows)\")\n",
        "print(f\"Holdout weeks: {unique_weeks[cutoff_idx]} – {unique_weeks[-1]}  \"\n",
        "      f\"({n_weeks - cutoff_idx} weeks, {len(ho_val_idx):,} rows)\")\n",
        "print(f\"Target rate — train: {y[ho_train_idx].mean():.4f}  \"\n",
        "      f\"holdout: {y[ho_val_idx].mean():.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "timings: dict[str, float] = {}\n",
        "\n",
        "# ── CatBoost ──────────────────────────────────────────────────\n",
        "t0 = time.perf_counter()\n",
        "ho_cb = CatBoostClassifier(\n",
        "    iterations=1000, **cb_best,\n",
        "    random_seed=42, eval_metric=\"AUC\",\n",
        "    cat_features=cat_cols, allow_writing_files=False,\n",
        ")\n",
        "ho_cb.fit(\n",
        "    X.iloc[ho_train_idx], y[ho_train_idx],\n",
        "    eval_set=(X.iloc[ho_val_idx], y[ho_val_idx]),\n",
        "    early_stopping_rounds=100, verbose=0,\n",
        ")\n",
        "ho_pred_cb = ho_cb.predict_proba(X.iloc[ho_val_idx])[:, 1]\n",
        "timings[\"CatBoost  (1 split)\"] = time.perf_counter() - t0\n",
        "\n",
        "# ── LightGBM ─────────────────────────────────────────────────\n",
        "t0 = time.perf_counter()\n",
        "ho_lgb = lgb.LGBMClassifier(\n",
        "    n_estimators=1000, **lgb_best,\n",
        "    random_state=42, verbose=-1,\n",
        ")\n",
        "ho_lgb.fit(\n",
        "    X_lgb.iloc[ho_train_idx], y[ho_train_idx],\n",
        "    eval_set=[(X_lgb.iloc[ho_val_idx], y[ho_val_idx])],\n",
        "    eval_metric=\"auc\",\n",
        "    callbacks=[lgb.early_stopping(100, verbose=False)],\n",
        ")\n",
        "ho_pred_lgb = ho_lgb.predict_proba(X_lgb.iloc[ho_val_idx])[:, 1]\n",
        "timings[\"LightGBM  (1 split)\"] = time.perf_counter() - t0\n",
        "\n",
        "# ── XGBoost (fold-safe encoding) ─────────────────────────────\n",
        "t0 = time.perf_counter()\n",
        "X_tr_h = X[lgb_feature_cols].iloc[ho_train_idx].copy()\n",
        "X_val_h = X[lgb_feature_cols].iloc[ho_val_idx].copy()\n",
        "\n",
        "ho_enc = CatBoostEncoder(cols=lgb_cat_cols, random_state=42)\n",
        "X_tr_h[lgb_cat_cols] = ho_enc.fit_transform(X_tr_h[lgb_cat_cols], y[ho_train_idx])\n",
        "X_val_h[lgb_cat_cols] = ho_enc.transform(X_val_h[lgb_cat_cols])\n",
        "\n",
        "ho_xgb = XGBClassifier(\n",
        "    n_estimators=1000, **xgb_best,\n",
        "    random_state=42, eval_metric=\"auc\",\n",
        "    tree_method=\"hist\", early_stopping_rounds=100, verbosity=0,\n",
        ")\n",
        "ho_xgb.fit(X_tr_h, y[ho_train_idx],\n",
        "           eval_set=[(X_val_h, y[ho_val_idx])], verbose=0)\n",
        "ho_pred_xgb = ho_xgb.predict_proba(X_val_h)[:, 1]\n",
        "timings[\"XGBoost   (1 split)\"] = time.perf_counter() - t0\n",
        "\n",
        "# ── Ensemble (simple average — no re-fitted meta-learner) ────\n",
        "ho_pred_ens = (ho_pred_cb + ho_pred_lgb + ho_pred_xgb) / 3\n",
        "\n",
        "# ── Data I/O baseline ────────────────────────────────────────\n",
        "t0 = time.perf_counter()\n",
        "_ = pl.read_parquet(Path(DATA_PATH) / \"processed\" / \"train_final.parquet\")\n",
        "timings[\"Load train parquet\"] = time.perf_counter() - t0\n",
        "\n",
        "print(\"Holdout training complete.\\n\")\n",
        "for stage, secs in timings.items():\n",
        "    print(f\"  {stage:<25} {secs:>7.1f}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "wk_val = week_num[ho_val_idx]\n",
        "y_val_ho = y[ho_val_idx]\n",
        "\n",
        "ho_results = {}\n",
        "for name, pred in [(\"CatBoost\", ho_pred_cb), (\"LightGBM\", ho_pred_lgb),\n",
        "                    (\"XGBoost\", ho_pred_xgb), (\"Ensemble(avg)\", ho_pred_ens)]:\n",
        "    auc_v = roc_auc_score(y_val_ho, pred)\n",
        "    stab_v = gini_stability(wk_val, y_val_ho, pred)\n",
        "    ho_results[name] = {\"auc\": auc_v, **stab_v}\n",
        "\n",
        "print(f\"{'═'*76}\")\n",
        "print(f\"  Pseudo-Future Holdout (weeks >{cutoff_week})\")\n",
        "print(f\"{'═'*76}\")\n",
        "print(f\"{'Model':<16} {'HO AUC':>9} {'HO Stab':>10}  \"\n",
        "      f\"{'CV AUC':>9} {'CV Stab':>10}  {'ΔAUC':>7} {'ΔStab':>7}\")\n",
        "print(f\"{'─'*76}\")\n",
        "cv_refs = [\n",
        "    (\"CatBoost\",      auc_cb_t,            stab_cb_t),\n",
        "    (\"LightGBM\",      auc_lgb_t,           stab_lgb_t),\n",
        "    (\"XGBoost\",       auc_xgb_t,           stab_xgb_t),\n",
        "    (\"Ensemble(avg)\", ensemble[\"oof_auc\"], stab_ens),\n",
        "]\n",
        "for (name, cv_auc, cv_stab) in cv_refs:\n",
        "    ho = ho_results[name]\n",
        "    da = ho[\"auc\"] - cv_auc\n",
        "    ds = ho[\"stability_score\"] - cv_stab[\"stability_score\"]\n",
        "    print(f\"{name:<16} {ho['auc']:>9.6f} {ho['stability_score']:>10.6f}  \"\n",
        "          f\"{cv_auc:>9.6f} {cv_stab['stability_score']:>10.6f}  \"\n",
        "          f\"{da:>+7.4f} {ds:>+7.4f}\")\n",
        "\n",
        "# Weekly Gini plot for holdout ensemble\n",
        "ginis_ho = ho_results[\"Ensemble(avg)\"][\"weekly_ginis\"]\n",
        "x_ho = np.arange(len(ginis_ho))\n",
        "sl = ho_results[\"Ensemble(avg)\"][\"slope\"]\n",
        "ic = np.mean(ginis_ho) - sl * np.mean(x_ho)\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(13, 4))\n",
        "ax.plot(x_ho, ginis_ho, \"o-\", color=\"#C44E52\", markersize=5, linewidth=1.2,\n",
        "        label=\"holdout weekly gini\")\n",
        "ax.plot(x_ho, sl * x_ho + ic, \"--\", color=\"#DD8452\", linewidth=1.5,\n",
        "        label=f\"trend (slope={sl:.5f})\")\n",
        "ax.axhline(ho_results[\"Ensemble(avg)\"][\"mean_gini\"], color=\"grey\",\n",
        "           linestyle=\":\", linewidth=0.8,\n",
        "           label=f\"mean gini = {ho_results['Ensemble(avg)']['mean_gini']:.4f}\")\n",
        "ax.set_xlabel(\"Holdout Week Index\")\n",
        "ax.set_ylabel(\"Gini (2·AUC − 1)\")\n",
        "ax.set_title(f\"Pseudo-Future Holdout — Ensemble Weekly Gini  \"\n",
        "             f\"(stability = {ho_results['Ensemble(avg)']['stability_score']:.4f})\")\n",
        "ax.legend(fontsize=9)\n",
        "fig.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "BUDGET_S = 12 * 3600  # 12-hour Kaggle CPU limit\n",
        "\n",
        "t_cb  = timings[\"CatBoost  (1 split)\"]\n",
        "t_lgb = timings[\"LightGBM  (1 split)\"]\n",
        "t_xgb = timings[\"XGBoost   (1 split)\"]\n",
        "t_io  = timings[\"Load train parquet\"]\n",
        "\n",
        "stages = {\n",
        "    \"Data loading (all tables)\":      t_io * 8,\n",
        "    \"Feature engineering\":            t_io * 12,\n",
        "    \"CatBoost  (5-fold CV)\":          t_cb  * 5,\n",
        "    \"LightGBM  (5-fold CV)\":          t_lgb * 5,\n",
        "    \"XGBoost   (5-fold CV + encode)\": t_xgb * 5,\n",
        "    \"Ensemble + I/O\":                 10.0,\n",
        "}\n",
        "\n",
        "total = sum(stages.values())\n",
        "total_min = total / 60\n",
        "\n",
        "print(f\"{'═'*56}\")\n",
        "print(f\"  Projected Kaggle Runtime (CPU-only)\")\n",
        "print(f\"{'═'*56}\")\n",
        "print(f\"  {'Stage':<36} {'Projected':>10}\")\n",
        "print(f\"  {'─'*48}\")\n",
        "for stage, secs in stages.items():\n",
        "    print(f\"  {stage:<36} {secs:>8.0f}s\")\n",
        "print(f\"  {'─'*48}\")\n",
        "print(f\"  {'TOTAL':<36} {total:>8.0f}s  ({total_min:.1f} min)\")\n",
        "print(f\"  {'Budget':<36} {BUDGET_S:>8.0f}s  ({BUDGET_S/3600:.0f} hr)\")\n",
        "margin = BUDGET_S - total\n",
        "print(f\"  {'Margin':<36} {margin:>8.0f}s  ({margin/60:.0f} min)\")\n",
        "\n",
        "pct = total / BUDGET_S * 100\n",
        "print(f\"\\n{'═'*56}\")\n",
        "if total > BUDGET_S:\n",
        "    print(f\"  OVER BUDGET — {pct:.0f}% of limit\")\n",
        "    print(f\"{'═'*56}\")\n",
        "    print(\"  Recommended trims:\")\n",
        "    print(\"    1. Cap n_estimators at 500 for all three models\")\n",
        "    print(\"       (early stopping already selects the best round)\")\n",
        "    print(\"    2. Reduce CatBoost depth to max 6\")\n",
        "    print(\"    3. Drop depth-2 aggregations (~30% fewer features,\")\n",
        "    print(\"       saves feature-eng and model training time)\")\n",
        "    print(\"    4. Skip CatBoost if LightGBM+XGBoost ensemble\")\n",
        "    print(\"       is within 0.001 stability of the 3-model stack\")\n",
        "else:\n",
        "    print(f\"  WITHIN BUDGET — {pct:.1f}% of 12-hour limit\")\n",
        "    print(f\"{'═'*56}\")\n",
        "    if pct > 70:\n",
        "        print(\"  Tight margin — consider these safety trims:\")\n",
        "        print(\"    - Cap n_estimators at 800 for all models\")\n",
        "        print(\"    - Limit depth-2 tables to applprev_2 only\")\n",
        "    elif pct > 40:\n",
        "        print(\"  Comfortable margin — no trimming needed.\")\n",
        "        print(\"  Optional: increase n_estimators to 1500 for\")\n",
        "        print(\"  potentially higher accuracy within budget.\")\n",
        "    else:\n",
        "        print(\"  Large margin available.  Safe to add:\")\n",
        "        print(\"    - More Optuna trials for finer tuning\")\n",
        "        print(\"    - Additional seed averaging (5 seeds)\")\n",
        "        print(\"    - Extra depth-1 tables if available\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}