{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Data Exploration\n",
        "\n",
        "Testing the data processing utilities with base table and static_0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"..\")\n",
        "\n",
        "import polars as pl\n",
        "from src.data_processing import (\n",
        "    load_table_group,\n",
        "    downcast_dtypes,\n",
        "    drop_high_missing_cols,\n",
        "    drop_high_cardinality_string_cols,\n",
        "    preprocess_table,\n",
        "    get_table_info,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "DATA_PATH = \"../data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Base Table"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load the base table\n",
        "base = load_table_group(DATA_PATH, \"base\", split=\"train\")\n",
        "print(f\"Base table shape: {base.shape}\")\n",
        "base.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check base table info\n",
        "get_table_info(base)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Preprocess base table\n",
        "base_processed = preprocess_table(base)\n",
        "print(f\"\\nAfter preprocessing: {base_processed.shape}\")\n",
        "get_table_info(base_processed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Static_0 Table\n",
        "\n",
        "This table has multiple chunks (static_0_0, static_0_1, etc.) that need to be concatenated."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Load static_0 - this will concatenate all chunks\n",
        "static_0 = load_table_group(DATA_PATH, \"static_0\", split=\"train\")\n",
        "print(f\"Static_0 table shape: {static_0.shape}\")\n",
        "static_0.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check static_0 info before preprocessing\n",
        "info_before = get_table_info(static_0)\n",
        "print(f\"Shape: {info_before['shape']}\")\n",
        "print(f\"Memory: {info_before['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Dtype counts: {info_before['dtype_counts']}\")\n",
        "print(f\"Columns with >50% missing: {len(info_before['columns_with_high_missing'])}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test downcast_dtypes\n",
        "static_0_downcasted = downcast_dtypes(static_0)\n",
        "info_downcasted = get_table_info(static_0_downcasted)\n",
        "print(f\"Memory before downcast: {info_before['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Memory after downcast: {info_downcasted['estimated_memory_mb']:.2f} MB\")\n",
        "print(f\"Memory reduction: {(1 - info_downcasted['estimated_memory_mb']/info_before['estimated_memory_mb'])*100:.1f}%\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test drop_high_missing_cols\n",
        "print(f\"Columns before: {static_0.shape[1]}\")\n",
        "static_0_no_missing = drop_high_missing_cols(static_0, threshold=0.98)\n",
        "print(f\"Columns after (threshold=0.98): {static_0_no_missing.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test drop_high_cardinality_string_cols\n",
        "static_0_no_high_card = drop_high_cardinality_string_cols(static_0, max_unique=10_000)\n",
        "print(f\"Columns after dropping high-cardinality strings: {static_0_no_high_card.shape[1]}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Apply full preprocessing pipeline\n",
        "static_0_processed = preprocess_table(static_0)\n",
        "print(f\"\\nFinal shape after full preprocessing: {static_0_processed.shape}\")\n",
        "get_table_info(static_0_processed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "The data processing utilities provide:\n",
        "- `load_table_group()`: Load and concatenate chunked parquet files\n",
        "- `downcast_dtypes()`: Reduce memory by casting float64→float32, int64→int32\n",
        "- `drop_high_missing_cols()`: Remove columns with missing rate > threshold\n",
        "- `drop_high_cardinality_string_cols()`: Remove string columns with too many unique values\n",
        "- `preprocess_table()`: Apply all preprocessing steps in one call"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}